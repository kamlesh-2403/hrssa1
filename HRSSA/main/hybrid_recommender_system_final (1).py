# -*- coding: utf-8 -*-
"""hybrid_recommender_system_final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iizbFAwSVS892wbyTkMfU9MZ25UcMSPx

# **Dependencies**
"""

from __future__ import print_function

import numpy as np
import pandas as pd
import collections
from mpl_toolkits.mplot3d import Axes3D
from IPython import display
from matplotlib import pyplot as plt
import sklearn
import sklearn.manifold
import tensorflow as tf
from sklearn import preprocessing
import time
import re
from gensim.models import word2vec
from keras.preprocessing.text import Tokenizer
from keras.preprocessing.sequence import pad_sequences
from sklearn.model_selection import train_test_split
import os
from keras.models import Sequential

from keras.layers import Embedding

tf.compat.v1.disable_eager_execution()

pd.options.display.max_rows = 10
pd.options.display.float_format = '{:.3f}'.format
def mask(df, key, function):
  """Returns a filtered dataframe, by applying function to key"""
  return df[function(df[key])]

def flatten_cols(df):
  df.columns = [' '.join(col).strip() for col in df.columns.values]
  return df

pd.DataFrame.mask = mask
pd.DataFrame.flatten_cols = flatten_cols

USER_RATINGS = False
#!pip install --upgrade -q gspread
#from google.colab import auth
#import gspread
#from oauth2client.client import GoogleCredentials

"""# **Load Dataset**"""

users_file = 'https://static.turi.com/datasets/millionsong/10000.txt'
songs_file = 'https://static.turi.com/datasets/millionsong/song_data.csv'

song_df_1 = pd.read_table(users_file, header = None)
song_df_1.columns = ['user_id', 'song_id', 'listen_count']

song_df_2 =  pd.read_csv(songs_file)

#song_df_1.head()

#song_df_2.head()

#print("artist =", len(song_df_2.artist_name.unique()))
#print("title =", len(song_df_2.title.unique()))

song_id_le = preprocessing.LabelEncoder()
song_id_le.fit(song_df_2.song_id)
song_df_2.song_id = song_id_le.transform(song_df_2.song_id)
song_df_1.song_id = song_id_le.transform(song_df_1.song_id)

user_id_le = preprocessing.LabelEncoder()
song_df_1.user_id = user_id_le.fit_transform(song_df_1.user_id)

song_df = pd.merge(song_df_1, song_df_2.drop_duplicates(['song_id']), on="song_id", how="left")

#song_df.describe(include=[np.int, np.object])

song_df = song_df.fillna(value=0)

#song_df.head(10)

# print("number of unique user =", len(pd.unique(song_df.user_id)))
# print("number of unique song =", len(pd.unique(song_df.song_id)))



"""# **Data Normalization**"""

zscore = lambda x: (x - x.mean()) / x.std()
# min_max = lambda x: (x - x.min()) / (x.max() - x.min())
norm = song_df.groupby('user_id').transform(zscore)
song_df.listen_count = norm.listen_count 

#song_df.tail()

min_max = lambda x: (x - x.min()) / (x.max() - x.min())
norm = song_df.groupby('user_id').transform(min_max)

song_df.listen_count = norm.listen_count 

#song_df.head()

song_df = song_df.fillna(value=0)

"""Collaborative Filtering Model"""

def split_dataframe(df, holdout_fraction=0.1):
  test = df.sample(frac=holdout_fraction, replace=False)
  train = df[~df.index.isin(test.index)]
  return train, test

def build_rating_sparse_tensor(song_df):
  
  indices = song_df[['user_id', 'song_id']].values
  values = song_df['listen_count'].values
  return tf.SparseTensor(
      indices=indices,
      values=values,
      dense_shape=[song_df_1.shape[0], song_df_2.shape[0]])

def sparse_mean_square_error(sparse_ratings, user_embeddings, music_embeddings):
  predictions = tf.reduce_sum(
      tf.gather(user_embeddings, sparse_ratings.indices[:, 0]) *
      tf.gather(music_embeddings, sparse_ratings.indices[:, 1]),
      axis=1)
  loss = tf.losses.mean_squared_error(sparse_ratings.values, predictions)
  return loss

import tensorflow.compat.v1 as tf
tf.disable_v2_behavior()
class CFModel(object):
  def __init__(self, embedding_vars, loss, metrics=None):
    
    self._embedding_vars = embedding_vars
    self._loss = loss
    self._metrics = metrics
    self._embeddings = {k: None for k in embedding_vars}
    self._session = None

  @property
  def embeddings(self):
    return self._embeddings

  def train(self, num_iterations=100, learning_rate=1.0, plot_results=True,
            optimizer=tf.train.GradientDescentOptimizer):
    with self._loss.graph.as_default():
      opt = optimizer(learning_rate)
      train_op = opt.minimize(self._loss)
      local_init_op = tf.group(
          tf.variables_initializer(opt.variables()),
          tf.local_variables_initializer())
      if self._session is None:
        self._session = tf.Session()
        with self._session.as_default():
          self._session.run(tf.global_variables_initializer())
          self._session.run(tf.tables_initializer())
          tf.train.start_queue_runners()

    with self._session.as_default():
      local_init_op.run()
      iterations = []
      metrics = self._metrics or ({},)
      metrics_vals = [collections.defaultdict(list) for _ in self._metrics]

      # Train and append results.
      for i in range(num_iterations + 1):
        _, results = self._session.run((train_op, metrics))
        if (i % 10 == 0) or i == num_iterations:
          print("\r iteration %d: " % i + ", ".join(
                ["%s=%f" % (k, v) for r in results for k, v in r.items()]),
                end='')
          iterations.append(i)
          for metric_val, result in zip(metrics_vals, results):
            for k, v in result.items():
              metric_val[k].append(v)

      for k, v in self._embedding_vars.items():
        self._embeddings[k] = v.eval()

      if plot_results:
        # Plot the metrics.
        num_subplots = len(metrics)+1
        fig = plt.figure()
        fig.set_size_inches(num_subplots*10, 8)
        for i, metric_vals in enumerate(metrics_vals):
          ax = fig.add_subplot(1, num_subplots, i+1)
          for k, v in metric_vals.items():
            ax.plot(iterations, v, label=k)
          ax.set_xlim([1, num_iterations])
          ax.legend()
      return results

def gravity(U, V):
  
  return 1. / (U.shape[0].value*V.shape[0].value) * tf.reduce_sum(
      tf.matmul(U, U, transpose_a=True) * tf.matmul(V, V, transpose_a=True))

def build_regularized_model(
    ratings, embedding_dim=3, regularization_coeff=.1, gravity_coeff=1.,
    init_stddev=0.1,U,V):
  
  train_ratings, test_ratings = split_dataframe(ratings)
  
  A_train = build_rating_sparse_tensor(train_ratings)
  A_test = build_rating_sparse_tensor(test_ratings)
  U = tf.Variable(tf.random_normal(
      [A_train.dense_shape[0], embedding_dim], stddev=init_stddev))
  V = tf.Variable(tf.random_normal(
      [A_train.dense_shape[1], embedding_dim], stddev=init_stddev))

  error_train = sparse_mean_square_error(A_train, U, V)
  error_test = sparse_mean_square_error(A_test, U, V)
  gravity_loss = gravity_coeff * gravity(U, V)
  regularization_loss = regularization_coeff * (
      tf.reduce_sum(U*U)/U.shape[0].value + tf.reduce_sum(V*V)/V.shape[0].value)
  total_loss = error_train + regularization_loss + gravity_loss
  losses = {
      'train_error_observed': error_train,
      'test_error_observed': error_test,
  }
  loss_components = {
      'observed_loss': error_train,
      'regularization_loss': regularization_loss,
      'gravity_loss': gravity_loss,
  }
  embeddings = {"user_id": U, "song_id": V}

  return CFModel(embeddings, total_loss, [losses, loss_components])

# reg_model = build_regularized_model(
#     song_df, regularization_coeff=0.1, gravity_coeff=1.0, embedding_dim=35,
#     init_stddev=.05)
# reg_model.train(num_iterations=200, learning_rate=20.)

DOT = 'dot' #data members left
COSINE = 'cosine'# data members left
def compute_scores(query_embedding, item_embeddings, measure=DOT):
  u = query_embedding
  V = item_embeddings
  if measure == COSINE:
    V = V / np.linalg.norm(V, axis=1, keepdims=True)
    u = u / np.linalg.norm(u)
  scores = u.dot(V.T)
  return scores

def music_neighbors(model, title_substring, measure=DOT, k=10):
  ids =  music[music['title']==title_substring].index.values
  titles = music.iloc[ids]['title'].values
  if len(titles) == 0:
    raise ValueError("Found no music with title %s" % title_substring)
  print("Nearest neighbors of : %s." % titles[0])
  if len(titles) > 1:
    print("[Found more than one matching music. Other candidates: {}]".format(
        ", ".join(titles[1:])))
  song_id = ids[0]
  scores = compute_scores(
      model.embeddings["song_id"][song_id], model.embeddings["song_id"],
      measure)
  score_key = measure + ' score'
  df = pd.DataFrame({
      score_key: list(scores),
      'titles': music['title'],
  })
  display.display(df.sort_values([score_key], ascending=False).head(k))

music = song_df_2
#music_neighbors(reg_model, "Colin", COSINE)

#music_neighbors(reg_model, "Colin", DOT)

USER_RATINGS = True #@param {type:"boolean"}
users = song_df_1

# if USER_RATINGS:
#   auth.authenticate_user()
#   gc = gspread.authorize(GoogleCredentials.get_application_default())
#   # Create the spreadsheet and print a link to it.
#   try:
#     sh = gc.open('music-test')
#   except(gspread.SpreadsheetNotFound):
#     sh = gc.create('music-test')

#   worksheet = sh.sheet1
#   titles = music['title'].values[0:1000] # take the first 100 songs
# #   titles = [re.sub(r'/\s+/g', '-', str(item)) for item in titles]
#   cell_list = worksheet.range(1, 1, len(titles), 1)
#   for cell, title in zip(cell_list, titles):
#     cell.value = title
#   worksheet.update_cells(cell_list)
#   print("Link to the spreadsheet: "
#         "https://docs.google.com/spreadsheets/d/{}/edit".format(sh.id))

def user_recommendations(model, measure=DOT, exclude_rated=False, k=20):
  if USER_RATINGS:
    scores = compute_scores(
        model.embeddings["user_id"][943], model.embeddings["song_id"], measure)
    score_key = measure + ' score'
    df = pd.DataFrame({
        score_key: list(scores),
        'song_id': music['song_id'],
        'titles': music['title'],
    })
    if exclude_rated:
      # remove music that are already rated
      rated_music = ratings[ratings.user_id == "943"]["song_id"].values
      df = df[df.song_id.apply(lambda song_id: song_id not in rated_music)]
    display.display(df.sort_values([score_key], ascending=False).head(k))

def model_obj(user_uuid,song_uuid):
    reg_model = build_regularized_model(
    song_df, regularization_coeff=0.1, gravity_coeff=1.0, embedding_dim=35,
    init_stddev=.05,user_uuid,song_uuid)
    reg_model.train(num_iterations=200, learning_rate=20.)
    return reg_model

# if USER_RATINGS:
#   user_recommendations(reg_model, measure=DOT, k=20)

#"""Content Based Recommender System"""
#
#music = song_df_2 
#song_name = music.title.values
#song_name_clean = [re.sub(r'[^\w]', ' ', str(item))for item in song_name]
#song_name_clean = [re.sub(r" \d+", '', str(item.strip())) for item in song_name_clean]
#
#sentences = list()
#for item in song_name_clean:
#  sentences.append(item.split())
#  
#unique_sentence = np.unique(sentences)
#
#num_features = 50                          
#min_word_count = 50                      
#num_workers = 1      
#context = 3         
#                                                                                                        
#downsampling = 1e-3  
#
#model_wv = word2vec.Word2Vec(unique_sentence, workers=num_workers, \
#            size=num_features, min_count = min_word_count, \
#            window = context, sample = downsampling)
#
#model_wv.init_sims(replace=True)
#
#model_wv.most_similar(u'Lost')
#
##Store the word2vec model
#corpus = sorted(model_wv.wv.vocab.keys()) 
#emb_tuple = tuple([model_wv[v] for v in corpus])
#X = np.vstack(emb_tuple)
#model_wv.wv.save_word2vec_format('song_tile_embedding.txt', binary = False)
#
#X = sentences
#EMBEDDING_DIM = num_features
#max_length = max([len(s) for s in X])
#
#tokenizer_obj = Tokenizer()
#tokenizer_obj.fit_on_texts(X)
#
#X_token = tokenizer_obj.texts_to_sequences(X)
#X_pad = pad_sequences(X_token, maxlen = max_length, padding = 'post')
#
#embeddings_index = {}
#f = open(os.path.join('','song_tile_embedding.txt'), encoding = 'utf-8')
#for line in f:
#    values = line.split()
#    word = values[0]
#    coefs = np.asarray(values[1:])
#    embeddings_index[word] = coefs
#    
#f.close()
#
#word_index = tokenizer_obj.word_index
#num_words = len(word_index) + 1
#
#embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))
#for word, i in word_index.items():
#    embedding_vector = embeddings_index.get(word)
#    if embedding_vector is not None:
#        # words not found in embedding index will be all-zeros.
#        embedding_matrix[i] = embedding_vector[-EMBEDDING_DIM:]
#
#model_wv_seq = Sequential()
#embedding_layer = Embedding(len(word_index) + 1,
#                            EMBEDDING_DIM,
#                            weights=[embedding_matrix],
#                            input_length=max_length,
#                            trainable=False)
#model_wv_seq.add(embedding_layer)
#model_wv_seq.compile(optimizer = 'adam', loss = 'mse')
#
#model_wv_seq.save_weights('model_wv_seq.hdf5')
#
## pick one unseen song
#
#old_songs = set(song_df_1.song_id.values)
#all_songs = set(song_df_2.song_id.values)
#
#unseen_song = all_songs- old_songs
#new_title = song_df_2[song_df_2.song_id == unseen_song.pop()].title
#
#new_sentences = list()
#for item in new_title:
#  new_sentences.append(item.split())
#  
#
#X_token = tokenizer_obj.texts_to_sequences(new_sentences)
#X_pad_new = pad_sequences(X_token, maxlen = max_length, padding = 'post')
#Song_vector_new = model_wv_seq.predict(X_pad_new)
#
#Song_vector_copy = Song_vector_new.copy()
#Song_vector_copy[Song_vector_copy == 0] = np.nan
#means_new_song = np.nanmean(Song_vector_copy, axis=1)
#
#Song_vector = model_wv_seq.predict(X_pad[0:16,:],  batch_size = 4)
#
#Song_vector_copy = Song_vector.copy()
#Song_vector_copy[Song_vector_copy == 0] = np.nan
#means = np.nanmean(Song_vector_copy, axis=1)
#
#from sklearn.metrics.pairwise import cosine_similarity
#scores = cosine_similarity(means[0].reshape(1, -1), means[2].reshape(1, -1))
#scores
#
#print(new_sentences)